{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Behavioral Cloning Project** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Behavioral Cloning Project**\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "* Use the simulator to collect data of good driving behavior\n",
    "* Build, a convolution neural network in Keras that predicts steering angles from images\n",
    "* Train and validate the model with a training and validation set\n",
    "* Test that the model successfully drives around track one without leaving the road\n",
    "* Summarize the results with a written report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rubric Points\n",
    "### Here I will consider the [rubric points](https://review.udacity.com/#!/rubrics/432/view) individually and describe how I addressed each point in my implementation.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Files Submitted & Code Quality\n",
    "\n",
    "#### 1. Submission includes all required files and can be used to run the simulator in autonomous mode\n",
    "\n",
    "My project includes the following files:\n",
    "* model.py containing the script to create and train the model\n",
    "* drive.py for driving the car in autonomous mode\n",
    "* model.h5 containing a trained convolution neural network \n",
    "* writeup_report.md or writeup_report.pdf summarizing the results\n",
    "* video.mp4 recording the autonomous driving process\n",
    "* utils.py containing the data preprocessing functions and data agumentation functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Submission includes functional code\n",
    "Using the Udacity provided simulator and my drive.py file, the car can be driven autonomously around the track and storing the driving images in run1 directory by executing \n",
    "```\n",
    "python drive.py model-005.h5 run1\n",
    "```\n",
    "\n",
    "Video.py is used to make a video of the vehicle when it is driving autonomously\n",
    "```\n",
    "python video.py run1\n",
    "```\n",
    "\n",
    "#### 3. Submission code is usable and readable\n",
    "\n",
    "The model.py file contains the code for training and saving the convolution neural network. The file shows the pipeline I used for training and validating the model, and it contains comments to explain how the code works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[//]: # (Image References)\n",
    "\n",
    "[image1]: ./examples/center_2018_08_30_18_18_51_568.jpg \"Driving Center Image\"\n",
    "[image2]: ./examples/left_2018_08_30_18_18_51_568.jpg \"Driving Left Image\"\n",
    "[image3]: ./examples/right_2018_08_30_18_18_51_568.jpg \"Driving Right Image\"\n",
    "[image4]: ./examples/center_2018_08_30_18_22_14_803.jpg \"Driving Counter-clockwise center Image\"\n",
    "\n",
    "### Data Collection Strategies\n",
    "\n",
    "#### 1. Center Driving\n",
    "The first collection strategy is try to make the car drive down the center of the road.\n",
    "So I drive the car by keyboard and mouse along the center of the track about four laps.\n",
    "\n",
    "These are the center, left, right images in the training set:\n",
    "\n",
    "![Center Image][image1]\n",
    "![Left Image][image2]\n",
    "![Right Image][image3]\n",
    "\n",
    "#### 2. Driving counter-clockwise\n",
    "Then I drive the car counter-clockwise along the track about two laps.\n",
    "\n",
    "The couter-clockwise data can help generalize the model.\n",
    "\n",
    "This is the counter-clockwise image in the training set:\n",
    "\n",
    "![Counter-clockwise Center Image][image4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[//]: # (Image References)\n",
    "\n",
    "[image1]: ./examples/index.png \"Original\"\n",
    "[image2]: ./examples/index1.png \"Preprocessing Image\"\n",
    "[image3]: ./examples/index3.png \"Augmentation Image\"\n",
    "\n",
    "### Data Preprocess and Data Augmentation\n",
    "The data preprocessing and agumentation functions are defined in the util.py which contains:\n",
    "    \n",
    "    Data preprocessing functions:\n",
    "    image cropping function: remove the sky at the top and the car front at the bottom\n",
    "    image resize function: resize the image to the input shape used by the network\n",
    "    convert rgb image to yuv format\n",
    "    \n",
    "Original image and preprocessing image:\n",
    "![Original][image1]\n",
    "![Proprocessing][image2]\n",
    "    \n",
    "    Data Augmentation functions:\n",
    "    random_flip: randomly filp the image from left to right and adjust the steering angle\n",
    "    random_translate: randomly shfit the image vertically and horizontally \n",
    "    random_shadow: generates and adds random shadow to the image\n",
    "    random_brightness: Randomly adjust brightness of the image.\n",
    "\n",
    "Original image and Augmentated image:\n",
    "![Original][image1]\n",
    "![Augmentation][image3]\n",
    "\n",
    "The Data preprocessing funtions are used to crop, resize the recording images, then converting the image format from rgb to yuv. These functions help us to avoid the influence of unrelated environment such as sky, ground truth and head of a car. \n",
    "\n",
    "The Data Augmentation are used to improve the data size which can avoid model overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture and Training Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[//]: # (Image References)\n",
    "\n",
    "[image1]: ./examples/Figure_1.png \"Model1 Result\"\n",
    "[image2]: ./examples/Figure_2.png \"Model2 Result\"\n",
    "[image3]: ./examples/Figure_3.png \"Model3 Result\"\n",
    "#### 1. First Model and Training without preprocessing and augumentation\n",
    "\n",
    "First Model Architecture:\n",
    "    \n",
    "    INPUT_SHAPE = (160, 320, 3)\n",
    "    \n",
    "    1 * Normaliztion Layer  \n",
    "    1 * Flatten Layer\n",
    "    1 * Fully Connected Layer\n",
    "    \n",
    "Training strategy:\n",
    "\n",
    "    model.compile(loss= 'mse', optimizer = 'adam')\n",
    "    model.fit(X_train, y_train, validation_split = 0.2, shuffle = True, nb_epoch = 5)\n",
    "    model.save('model.h5')\n",
    "    \n",
    "Model Results:\n",
    "![Results][image1]\n",
    "\n",
    "Train on 5907 samples, validate on 1477 samples\n",
    "#### 2. Second Model and Training without preprocessing and augumentation\n",
    "\n",
    "The Second Model is the lenet which is used in the traffic_sign_classifiy\n",
    "\n",
    "Second Model Architecture:\n",
    "    \n",
    "    INPUT_SHAPE = (160, 320, 3)\n",
    "    1 * Normaliztion Layer\n",
    "    1 * Cropping Layer\n",
    "    1 * Convolution Layer\n",
    "    1 * Pooling Layer\n",
    "    1 * Convolution Layer\n",
    "    1 * Pooling Layer\n",
    "    1 * Flatten Layer\n",
    "    3 * Fully Connected Layer\n",
    "    \n",
    "    Training strategy:\n",
    "\n",
    "    model.compile(loss= 'mse', optimizer = 'adam')\n",
    "    model.fit(X_train, y_train, validation_split = 0.2, shuffle = True, nb_epoch = 5)\n",
    "    model.save('lenet-model.h5')\n",
    "    \n",
    "Model Results:\n",
    "![Results][image2]\n",
    "\n",
    "Train on 5907 samples, validate on 1477 samples\n",
    "#### 3. Third Model and Training without preprocessing\n",
    "\n",
    "The Third model Architecture is the same as 2016 Nvidia self-driving car model\n",
    "\n",
    "Third Model Architecture:\n",
    "    \n",
    "    INPUT_SHAPE = (160, 320, 3)\n",
    "    1 * Normaliztion Layer\n",
    "    1 * Convolution Layer\n",
    "    1 * Pooling Layer\n",
    "    1 * Convolution Layer\n",
    "    1 * Pooling Layer\n",
    "    1 * Convolution Layer\n",
    "    1 * Pooling Layer\n",
    "    1 * Convolution Layer\n",
    "    1 * Pooling Layer\n",
    "    1 * Dropout Layer\n",
    "    1 * Flatten Layer\n",
    "    4 * Fully Connected Layer\n",
    "    \n",
    "    Training strategy:\n",
    "\n",
    "    model.compile(loss= 'mse', optimizer = 'adam')\n",
    "    model.fit(X_train, y_train, validation_split = 0.2, shuffle = True, nb_epoch = 5)\n",
    "    model.save('nvidia-model.h5')\n",
    "    \n",
    "Model Results:\n",
    "![Results][image3]\n",
    "Train on 5907 samples, validate on 1477 samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Results Analyses\n",
    "\n",
    "First Model: The first model has only three layers and the convergence rate is slow. The result is easy to fall into local optimum. After training, the car cannot drive stably.\n",
    "\n",
    "\n",
    "Second Model: So I decide to increase the model layers and import convolution layer and pooling layer, this training result of this model can let the car driving stably in the direct lane but will drive off the road when comes to corners.\n",
    "\n",
    "\n",
    "Third Model: I think the lenet is good at classfiy the traffic signs but not good at perdicting the steering angle for self-driving cars. The thrid model is found in the 2016 paper proposed by Nvidia which turns out to be a better model for self-driving cars. Initially the model is trained on 5907 samples and validate on 1477 samples. The reasons for the unsmooth loss oscillation are as follows:\n",
    "\n",
    "\n",
    "(1) the learning rate may be too large.\n",
    "\n",
    "\n",
    "(2) batch size is too small.\n",
    "\n",
    "\n",
    "(3) uneven distribution of samples\n",
    "\n",
    "\n",
    "(4) adding regularization\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Training Strategy\n",
    "\n",
    "In order to prevent these problems, the batch is increasing from 20 to 40, the samples are disributed evenly by data augmentation and the learing rate changes to 1.0e-4.  \n",
    "\n",
    "    # Parser for command-line options, arguments and sub-commands\n",
    "    parse = argparse.ArgumentParser(description='Car Behavioral Cloning Project')\n",
    "    parse.add_argument('-d', help='data directory', dest='data_dir', type=str, default='data')\n",
    "    parse.add_argument('-t', help='test size fraction', dest='test_size', type=float, default=0.2)\n",
    "    parse.add_argument('-n', help='number of epochs', dest='nb_epoch', type=int, default=6)\n",
    "    parse.add_argument('-k', help='drop out probability', dest='keep_prob', type=float, default=0.5)\n",
    "    parse.add_argument('-s', help='samples per epoch', dest='samples_per_epoch', type=int, default=20000)\n",
    "    parse.add_argument('-b', help='batch sizes', dest='batch_size', type=int, default=40)\n",
    "    parse.add_argument('-l', help='learning rate', dest='learning_rate', type=float, default=1.0e-4\n",
    "    \n",
    "Because the data augumentation increases the size of training images, the fit_generator is used to save memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
